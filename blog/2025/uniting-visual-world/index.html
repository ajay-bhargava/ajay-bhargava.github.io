<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Uniting the digital and visual world With Context | Ajay Bhargava Ph.D. </title> <meta name="author" content="Ajay Bhargava Ph.D."> <meta name="description" content="A call to action to unite the digital and visual world with AI agents and AR glasses."> <meta name="keywords" content="ai-enginer, ml-engineer, full-stack-engineer, fractional-cto, bench-scientist"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%94&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ajay-bhargava.github.io/blog/2025/uniting-visual-world/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Ajay Bhargava Ph.D. </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Uniting the digital and visual world With Context</h1> <p class="post-meta"> Created on July 04, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> ¬† ¬∑ ¬† <a href="/blog/tag/ar"> <i class="fa-solid fa-hashtag fa-sm"></i> ar</a> ¬† <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> ai</a> ¬† <a href="/blog/tag/agents"> <i class="fa-solid fa-hashtag fa-sm"></i> agents</a> ¬† <a href="/blog/tag/context"> <i class="fa-solid fa-hashtag fa-sm"></i> context</a> ¬† ¬∑ ¬† <a href="/blog/category/machine-learning-posts"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning-posts</a> </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#foreword-into-augmented-reality-ar">Foreword into Augmented Reality (AR)</a></li> <li class="toc-entry toc-h2"><a href="#what-do-the-brains-biological-limitations-tell-us">What do the brain‚Äôs biological limitations tell us?</a></li> <li class="toc-entry toc-h2"> <a href="#what-can-we-learn-from-the-army">What can we learn from the Army?</a> <ul> <li class="toc-entry toc-h3"><a href="#thank-you-to-our-military-service-members">Thank you to our military-service members</a></li> <li class="toc-entry toc-h3"> <a href="#using-well-designed-decision-support-ar-systems">Using well designed decision support AR systems</a> <ul> <li class="toc-entry toc-h4"><a href="#1-cognitive-bandwidth-is-a-ux-constraint">1. Cognitive bandwidth is a UX constraint</a></li> <li class="toc-entry toc-h4"><a href="#2-data-relevance-beats-quality">2. Data relevance beats quality</a></li> <li class="toc-entry toc-h4"><a href="#3-intuitive-symbols-leverage-your-visual-cortex">3. Intuitive symbols leverage your visual cortex</a></li> <li class="toc-entry toc-h4"><a href="#4-make-the-ai-output-aligned-with-the-visual-scene">4. Make the AI output aligned with the visual scene</a></li> <li class="toc-entry toc-h4"><a href="#5-leverage-attention-to-be-relevant-but-not-annoying">5. Leverage attention to be relevant but not annoying</a></li> <li class="toc-entry toc-h4"><a href="#summary">Summary</a></li> </ul> </li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#how-will-ar-powered-with-context-be-more-delightful-to-us-than-smartphones">How will AR powered With Context be more delightful to us than smartphones?</a> <ul> <li class="toc-entry toc-h3"><a href="#they-will-provide-context-not-experiences">They will provide Context, not ‚ÄúExperiences‚Äù</a></li> <li class="toc-entry toc-h3"><a href="#monetization-is-ambient-and-quality-reinforcing">Monetization is ambient and quality reinforcing</a></li> <li class="toc-entry toc-h3"><a href="#deliver-actionable-insight-not-just-delight">Deliver actionable insight, not just delight</a></li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#existing-participants-that-lower-the-barrier">Existing participants that lower the barrier</a> <ul> <li class="toc-entry toc-h3"> <a href="#software-infrastructure">Software Infrastructure</a> <ul> <li class="toc-entry toc-h4"><a href="#note-about-mentra">Note about Mentra</a></li> </ul> </li> <li class="toc-entry toc-h3"><a href="#vllm-models">vLLM models</a></li> <li class="toc-entry toc-h3"><a href="#digital-ai-agent-makers">Digital AI agent makers</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#development-plan">Development Plan</a></li> <li class="toc-entry toc-h2"><a href="#further-business-opportunities">Further business opportunities</a></li> <li class="toc-entry toc-h1"><a href="#summary-1">Summary</a></li> </ul> </div> <hr> <div id="markdown-content"> <h2 id="foreword-into-augmented-reality-ar">Foreword into Augmented Reality (AR)</h2> <p>There are two equally rich worlds. The real world we move through (the visual world), and the digital world of the internet, books, data servers, and LLM‚Äôs that live stationary at fixed entry points such as laptops, phones, and increasingly on audio interface touch points.</p> <p>Our brains are not designed to unite the vast visual world with the equally vast digital world. As a consequence of this fact, I believe that AR embedded with AI empowered assisted decision support software systems that bridge these two worlds represents the same gain of function for society to the extent ChatGPT empowered humanity to conquer the digital world.</p> <h2 id="what-do-the-brains-biological-limitations-tell-us">What do the brain‚Äôs biological limitations tell us?</h2> <p>From the retinal photoreceptors to our occipital lobes, a daisy-chain of hierarchically organized neurons of many kinds achieve 1000:1 compression of our visual world into concise information that can be reasoned with by our brains in real time. The net effect of this is that you never think about 99.9% of what your eyes see because an entire visual executive ‚Äúassistive‚Äù repertoire is ‚Äúhandling it‚Äù before the rest of your brain needs to care about it.</p> <p>Reading can, by comparison, feel efficient when content is compressed. Yet, it becomes inefficient as character count you read grows in size. This is because text is symbolic and linear. Yes, syntactically, language is compressed, but requires sequential decoding to make sense of it even when focused solely on reading. This fundamental difference becomes even more clear when what you read earlier has to be paired with live visual input you‚Äôre seeing now.</p> <p>Why do we suck at this task? It‚Äôs our biology and an evolutionary legacy! Separate neural subsystems are engaged between text (Broca‚Äôs, Wernike‚Äôs areas) and vision (V1-V4, IT). These systems are operating in parallel. Integration between these two neural subsystems only happens in higher order neural structures such as your prefrontal cortex and that structure is slow and capacity limited. There‚Äôs also little pre-computation of text compared to visual information. The hierarchy of daisy-chained visual neurons enables pre-compilation of visual information. There is no such hierarchy for language based information. From a biological standpoint it justifies why tools like GPT that summarize, diagram etc., have taken off in such a dramatic way: these models offload and ‚Äúassist‚Äù the job that your pre-frontal cortex used to spend manual cycles on onto a external digital-organ that pre-processes this for you.</p> <p>You‚Äôve probably unknowingly got an intuition of how humanity has mitigated for our evolutionary bottleneck and why it gives us delight when pre-computation of the visual and digital world is done for you (and makes others money). If you‚Äôve looked at an ad or just about any marketing you‚Äôll know that great marketing is a combination of highly compressed text and visual cues that‚Äôs insightful, actionable, and persuasive. Someone has done the visual and textual pre-computation to make the process of making (or swaying) a decision for you trivially easy.</p> <blockquote class="callout callout-important"> <p>Anywhere money is made through rapid perception and low-effort cognition you will find systems that pre-compute visual-text mappings.</p> </blockquote> <p>First, computer vision models parallelized visual computation to beyond the parallelization limit of human abilities. Then, LLM‚Äôs became the de-facto extra-corporeal organ for textual pre-computation. What‚Äôs next? I think its application of AI that uses multi-modal input prompts that is then in turn used to unlock and gather from the vast digital world by commanding networks of AI agents. Returned information has to be thoughtfully compressed using AI at the interface that people would derive the most delight from being able to act upon this information.</p> <p>Finding the right visual cues to unlock the right access of the relevant digital information in a way thats thoughtful and actionable is the core concept of a decision intelligence SDK and tooling layer that I want to build for the world.</p> <h2 id="what-can-we-learn-from-the-army">What can we learn from the Army?</h2> <h3 id="thank-you-to-our-military-service-members">Thank you to our military-service members</h3> <p>I spent months working intensively on projects with AFC (now TRADOC) when I was at Actuate and that culminated in a test of my work in a life-fire exercise on a base (poorly pictured below - lets just say an M109A7 firing down range will scare the shit out of you). I might look like a total dork here but it was honestly one of the most humbling and informative learning experiences of my life. I am truly humbled by our service-members. Without this there would be no concept of ‚ÄúWith Context‚Äù.</p> <p><img src="https://with-context-public.s3.us-east-1.amazonaws.com/internal-memory-documents/2025/07/4ad64a26ce60435fd5fa496797c16bf8.jpg" alt="image" width="100%"></p> <h3 id="using-well-designed-decision-support-ar-systems">Using well designed decision support AR systems</h3> <p>The U.S. Army and other military branches have decades of R&amp;D into heads-up-display (HUD) systems. You‚Äôve probably seen them mounted on guns, mounted on pilots and lately in autonomous tracking. There are many design philosophies in cognitive ergonomics, information compression, and perceptual prioritization that help enforce I perceive how humans <em>should</em> experience AI that‚Äôs embedded in decision support interfaces such as AR glasses.</p> <h4 id="1-cognitive-bandwidth-is-a-ux-constraint">1. Cognitive bandwidth is a UX constraint</h4> <p><em>Too much data ‚â† better decisions</em></p> <p>ChatGPT can‚Äôt help but spit out just gobs of text. Its insanity. The training runs responsible for aligned AI systems contribute to this problem. So much effort is put into libraries that constrain or structure these generations. The military has a clear doctrine on this:</p> <h4 id="2-data-relevance-beats-quality">2. Data relevance beats quality</h4> <p><em>Offer useful data, don‚Äôt offer useless data.</em></p> <p>Intriguingly, early HUD‚Äôs were poorly adopted because they dumped raw telemetry (altitude, speed, bearing) at all times in all contexts. Ever sit on an airplane today? Yeah, what good is knowing the distance to your destination when you‚Äôre landed at your destination? Or even the ground speed? Pointless.</p> <h4 id="3-intuitive-symbols-leverage-your-visual-cortex">3. Intuitive symbols leverage your visual cortex</h4> <p><em>Sprites and emojis are your friends</em></p> <p>Your mind is adapted to visual context and visual memory! Use it. Taking advantage of standardized symbols (think: Stop Sign, Warning, Road Closed) that are engrained in our visual memory is key to making the decisions actionable.</p> <h4 id="4-make-the-ai-output-aligned-with-the-visual-scene">4. Make the AI output aligned with the visual scene</h4> <p><em>Use vLLM‚Äôs to obfuscate prompting/programming</em></p> <p>One of the fastest ways to have HUD be unusable is to have them deliver context that isn‚Äôt relevant in that moment, that isn‚Äôt ephemeral and is high latency. These were impossible barriers to cross not more than 1 year ago as vLLM‚Äôs were still in their infancy. Fortunately, companies like <a href="http://moondream.ai" rel="external nofollow noopener" target="_blank">Moondream</a>are tackling this problem head on. Tiny LLM‚Äôs are the rage now, Tiny vLLM‚Äôs are the next.</p> <h4 id="5-leverage-attention-to-be-relevant-but-not-annoying">5. Leverage attention to be relevant but not annoying</h4> <p><em>Don‚Äôt be annoying</em></p> <p>Ok this one isn‚Äôt from the military but brought up from a Bronx native - yes, <a href="https://youtu.be/AWN8VmCTXAU?si=vUBhRzLY2wdDk2M-" rel="external nofollow noopener" target="_blank">Chris Hayes</a>. In an interview with Hasan Minhaj he talks about his book about human attention. Specifically, there are two kinds of attention: voluntary, and compelled. We are subjected to compelled attention mechanisms (e.g. car is honking, should I respond? Phone is buzzing, should I respond?). In things like AR glasses we have to be mindful of the fact that the wearer likely has one other device in his pocket begging for his attention. The Apple Watch has done a better job of being less attention seeking and therefore more relevant (I think). Similarly for UX design we have to think carefully about how the interface is to wield your attention and then unwield it just as fast so as to prevent fatigue, feel ambient, and feel ephemeral. This ephemeral, context driven nature of the equation is also key for a business model here.</p> <h4 id="summary">Summary</h4> <p>A friend and collaborator once told me that wearable AR tech for decision-making should feel like the difference between a good executive assistant (EA) and a bad one. I‚Äôve never had an EA myself, but here‚Äôs how I imagine it. If you‚Äôre heading up an elevator to a big boardroom meeting, the good EA is prepping you on the way up. They‚Äôre making sure the critical context is top of mind right before you walk in. That‚Äôs how good military HUD systems work. A solid AR decision support system ensures you‚Äôre not just present, but prepared. It makes you capable in ways that go beyond what you could manage alone.</p> <p>The hackathon where we built ‚ÄúEyyyyWear‚Äù was our way of pressure-testing this idea. It forced us to build AI agent overlays under real constraints. As developers, we felt those constraints in code. Delivering decision support while humans are in motion is not easy. But that‚Äôs where the value shows up. You check if a parking spot is open while your car is still moving. Why? So you can stay nimble in your car, avoid wasting time, and skip a parking ticket all while keeping your hands on the wheel.</p> <p>The hackathon at Betaworks was just an example. The larger point is that these systems are most useful when they meet you in real time, in your flow, in-context. The word ‚Äúcontext‚Äù really matters here because its a sharp break from the way smartphone apps were designed. Lets get into that next.</p> <h2 id="how-will-ar-powered-with-context-be-more-delightful-to-us-than-smartphones">How will AR powered <code class="language-plaintext highlighter-rouge">With Context</code> be more delightful to us than smartphones?</h2> <p>In the era of smartphones: users tap icons, add text, and scroll through apps bought on app stores. Your world is inside the app. In the wearable AR world, I believe that real world is your interface. What appears in your AR glasses while you‚Äôre in the real world is driven by the contexts you subscribe to. <code class="language-plaintext highlighter-rouge">Contexts</code> are overlaid AI agents that use images as sophisticated prompts to other models and leverage other AI agents to provision digital datasets to bring meaning to your visual world. I‚Äôd love to use this next section to make a case for the fundamental shift between apps and contexts.</p> <h3 id="they-will-provide-context-not-experiences">They will provide <code class="language-plaintext highlighter-rouge">Context</code>, not ‚ÄúExperiences‚Äù</h3> <p>The smartphone app is an ‚Äúintention-driven‚Äù interaction. You buy it, you touch its interface, you let the app decide, you share your experience on it with others. Whether you‚Äôre present in our earthly environment or not is beside the point when using an app. You‚Äôve probably seen this when you‚Äôre with your friends and they go on their phones. When they‚Äôre on the app, they‚Äôre <em>in</em> the app. The app is running in their mental foreground, and the developers who created the app have curated the runtime ‚Äúenvironment‚Äù to keep you engaged. Monetization in the app model is dependent on how much more of the app you want to lock into. Humanity has adapted, and subsequently become fatigued, to the concept and economics of the ‚Äúapp‚Äù.</p> <p>In AR, because the visual world is the interface, we‚Äôll be accessing <strong>different</strong> overlay AI agents that own and curate relevant context to your interface at that moment. I call them <code class="language-plaintext highlighter-rouge">Contexts</code> for short. They wont be something you touch, or intentionally download, they will function specific to visual context. You will be the decision engine, not the app. The net effect of this is: you won‚Äôt have to unravel structured visual understanding into low bitrate ‚Äúwords‚Äù with your brain, <code class="language-plaintext highlighter-rouge">Contexts</code> will see what you see and do what you normally would‚Äôve done with your phone to aid your decision making. I believe this will be of higher use to society than apps ever were.</p> <p><img src="https://with-context-public.s3.us-east-1.amazonaws.com/internal-memory-documents/2025/07/8e7e3e3df2f285fb45ede004c3c60428.png" alt="image" width="100%"></p> <h3 id="monetization-is-ambient-and-quality-reinforcing">Monetization is ambient and quality reinforcing</h3> <p>With smartphone apps, you are paying money detach yourself from the visual world. You then pay even more money for more expensive applications that promise that with AI and AI agents, your time on the app and therefore the length of time you‚Äôre detached from the world will shorten.</p> <p>I think the monetization strategy of ‚Äúeyeball commitment‚Äù is one ripe to be flipped on its head. It goes without saying that desktop class applications like ‚ÄúCluely‚Äù which bring decision intelligence as a service to the desktop have scratched a societal itch on this exact business model. To me, this provides validation that we‚Äôre touching a very real sore-spot that‚Äôs driven by our biology. Cluely‚Äôs business model, however, is still very SaaS centric ($20/month) because it lives atop other SaaS applications.</p> <p>I believe we should monetize those AI‚Äôs that best function in the digital world where it ‚Äúsees best‚Äù, and shepherd that returned information back to the physical one where we ‚Äúsee‚Äù best. Instead of paying to unlock an app, you pay to unlock the right ‚ÄúContexts‚Äù for you.</p> <table> <thead> <tr> <th>Apps</th> <th>Contexts</th> </tr> </thead> <tbody> <tr> <td>App Purchase</td> <td>No fee to download the ‚ÄúContext Platform‚Äù</td> </tr> <tr> <td>App Store fees</td> <td>Usage fee for different Contexts</td> </tr> <tr> <td>In-app purchases</td> <td>Higher usage fee for more involved, deeper knowledge parsing or more computationally complex AI agents that require longer reasoning</td> </tr> </tbody> </table> <hr> <h3 id="deliver-actionable-insight-not-just-delight">Deliver actionable insight, not just delight</h3> <p>Most apps don‚Äôt leave you with an ‚Äúactionable‚Äù insight, despite leaving you delighted by the UX, UI or a combination of the two. Owing to the constrained interfaces of a heads up display on a pair of glasses, outputs need to be short, punchy, and to the point. Designing for this constraint has to exist at the core cultural level of any ‚ÄúContext‚Äù creator. With Context will provide the MCP adaptors, tooling, and even other models in the loop to ensure that the user experience is actionable and purposeful.</p> <h2 id="existing-participants-that-lower-the-barrier">Existing participants that lower the barrier</h2> <h3 id="software-infrastructure">Software Infrastructure</h3> <p>Every AR device manufacturer has some form of a developer SDK that enables device level control of the hardware. <a href="https://github.com/Mentra-Community/MentraOS?tab=readme-ov-file" rel="external nofollow noopener" target="_blank">Mentra OS</a> is no exception here, providing abstraction over multiple devices to enable developers to readily create applications for a suite of AR glasses.</p> <p><img src="https://with-context-public.s3.us-east-1.amazonaws.com/internal-memory-documents/2025/07/50c006594f9e6c81ebe88c5d66fd2a48.png" alt="image" width="100%"></p> <h4 id="note-about-mentra">Note about Mentra</h4> <p>MentraOS and Mentra Merge are upcoming products alongside Mentra‚Äôs glasses. They are also cognizant about AI agents and I believe are well suited to produce the sort of AI overlay context agents I am talking about.</p> <h3 id="vllm-models">vLLM models</h3> <p>There are an increasing number of vLLM makers, most notably <a href="https://moondream.ai" rel="external nofollow noopener" target="_blank">Moondream.ai</a>who are uniquely solving both minification of vLLM‚Äôs and also increasing model throughput and inference speed. These represent important bridges between the visual and digital world.</p> <h3 id="digital-ai-agent-makers">Digital AI agent makers</h3> <p>It goes without saying that this venture cannot exist without an ever growing army of AI agents and MCP servers making their way into production grade applications. Even just 1 year ago when some of these AR devices were manufactured and sold for the first time, the concept of AI agents did not exist. Deeper and potentially interesting enterprise grade integrations using digital AI agents will fuel interesting use cases for AR ‚ÄúContexts‚Äù.</p> <h2 id="development-plan">Development Plan</h2> <table> <thead> <tr> <th style="text-align: center">Level</th> <th>Focus</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td>Validate a Device SDK</td> <td>Despite the fact that there are hardware SDK providers, not all devices are on the same SDK framework (e.g. Typescript). Fortunately most do have the underlying primitives and open documentation to get started.</td> </tr> <tr> <td style="text-align: center">2</td> <td>Prototype/Sell manually designed use case</td> <td>We previously demo‚Äôed EyyyWear for a parking use case, and have eyes on other more monetizable use cases in sales and potentially sports applications to gauge business interest. We will leverage existing tooling and platform where possible to deploy quickly.</td> </tr> <tr> <td style="text-align: center">3</td> <td>Survey the landscape of AI Agents suitable for Context Platform</td> <td>Qualify sustained interest and pitch if other contexts (overlay AI agents) would be useful in a decision intelligence setting.</td> </tr> <tr> <td style="text-align: center">4</td> <td>Design Context Subscription Platform</td> <td>If sustained interest is yielded then we will move into designing a context subscription platform ‚Äúapp‚Äù that will serve as the ‚Äúapp platform‚Äù or ‚Äústore‚Äù for multiple contexts.</td> </tr> <tr> <td style="text-align: center">5</td> <td>Create adaptors for existing MCP‚Äôs or SDK for AI agents (or create new MCP‚Äôs)</td> <td>Some business interesting AI agents might not be suitable for decision intelligence, they will need to be modified or adapted to functionally return actionable insights or intelligence.</td> </tr> <tr> <td style="text-align: center">6</td> <td>Automate decision intelligence with novel AI models and evaluate existing vLLM models</td> <td>We will need to better prompt or fine-tune an AI to tailor responses to be actionable for decision support given diverse outputs from multiple Contexts and multiple visual world inputs.</td> </tr> <tr> <td style="text-align: center">8</td> <td>Evaluate AR hardware performance for future use cases</td> <td>We may need to progress to developing our own hardware to better suit AI / AR needs.</td> </tr> </tbody> </table> <hr> <h2 id="further-business-opportunities">Further business opportunities</h2> <p>Here are some example uses that one could use <code class="language-plaintext highlighter-rouge">With Context</code>‚Äôs <code class="language-plaintext highlighter-rouge">Context</code> agents in:</p> <table> <thead> <tr> <th><strong>Trigger</strong></th> <th><strong>Overlay Response</strong></th> <th>Context Agent Complexity</th> </tr> </thead> <tbody> <tr> <td>üëÄ Look at a restaurant</td> <td>Show Yelp score, menu, wait time</td> <td>Low</td> </tr> <tr> <td>ü§≤ Hold a prescription bottle</td> <td>Show dosage instructions, and number of refills available.</td> <td>Low</td> </tr> <tr> <td>üîß Face HVAC equipment</td> <td>Show when the next filter change ought to happen.</td> <td>Medium</td> </tr> <tr> <td>üì∏ Gaze at a person at a sales event</td> <td>Show lead history, next action, notes.</td> <td>High</td> </tr> </tbody> </table> <hr> <p>There really are a number of use-cases that could also be worked on with branded partnerships such as those with sports leagues for entertainment or enhanced insights for fans who would appreciate that level of engagement.</p> <h1 id="summary-1">Summary</h1> <p>Augmented reality (AR) and artificial intelligence (AI) together offer a powerful method to bridge the visual and digital worlds, addressing our human cognitive limit. Our brains naturally separate visual and textual information into different processing pathways, leading to inefficiencies when integrating both simultaneously. A fundamental shift in monetization from traditional app-driven models to context-driven overlays can enhance user experience significantly. Fortunately, the existing ecosystem already includes robust infrastructure such as device SDKs, streamlined visual-language models (vLLMs), and advanced digital AI agents, providing a solid foundation for developing <code class="language-plaintext highlighter-rouge">Contexts</code>. If actionable intelligence <code class="language-plaintext highlighter-rouge">With Context</code> sounds interesting to you, reach out to me! I am building in this space.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Ajay Bhargava Ph.D.. Last updated: October 05, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>